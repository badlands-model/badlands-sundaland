{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import libpysal\n",
    "import esda\n",
    "\n",
    "import meshio\n",
    "\n",
    "from scipy import stats\n",
    "from scripts import morphoGrid as morph\n",
    "\n",
    "# display plots in SVG format\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract required information\n",
    "\n",
    "First we get the elevation from `badlands` output for a given time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 700\n",
    "dx = 5000.\n",
    "folder = 'lem-models/Sarr/h5'\n",
    "\n",
    "badland_topo = morph.morphoGrid(folder=folder, bbox = None, dx=dx)\n",
    "badland_topo.loadHDF5(timestep=step)\n",
    "\n",
    "# Regular grid coordinates\n",
    "xyi = np.dstack([badland_topo.x.flatten(), badland_topo.y.flatten()])[0]\n",
    "vertices = badland_topo.vertices\n",
    "XY = vertices[:,:2]\n",
    "elev = vertices[:,-1] - badland_topo.sl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, like for previous notebooks, we find the Sunda Shelf coordinates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelfXYZ = \"data/sundaland_shelf_coordinates.csv\"\n",
    "pd_shelf = pd.read_csv(\n",
    "            shelfXYZ,\n",
    "            sep=r\"\t\",\n",
    "            engine=\"c\",\n",
    "            na_filter=False,\n",
    "            dtype=np.float,\n",
    "            low_memory=False,\n",
    "        )\n",
    "\n",
    "shelfXY = pd_shelf.values[:, 0:2]\n",
    "shelfZ = pd_shelf.values[:, 2]\n",
    "tree = cKDTree(shelfXY)\n",
    "dists, inds = tree.query(XY, k=1)\n",
    "shelfIDs = np.where(np.logical_and(dists<=5000, elev>0.))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we specify the circuitscape `ASC` output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitscape  = 'cost/Sarr_700_corridor_cum_curmap.asc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute z-score\n",
    "\n",
    "To normalize connectivity over time, we will compute current flow z-score values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_current_zscore(file):\n",
    "    \n",
    "    curmap1  = np.flipud(np.loadtxt(file, skiprows=6))\n",
    "\n",
    "    iddd = np.where(curmap1.flatten()>0)[0]\n",
    "\n",
    "    posflow = curmap1.flatten()[iddd]\n",
    "    vals = stats.zscore(posflow, axis=0) #, ddof=1, nan_policy='raise')\n",
    "\n",
    "    tree = cKDTree(xyi) \n",
    "    res1 = curmap1.flatten()\n",
    "\n",
    "    # On the uniform grid\n",
    "    distances, indices = tree.query(XY, k=3)\n",
    "\n",
    "    onIDs = np.where(distances[:, 0] == 0)[0]\n",
    "    inIDs = np.where(distances[:, 0] > 0)[0]\n",
    "\n",
    "    weights = np.ones(distances.shape)\n",
    "    weights[inIDs,:] = 1.0 / distances[inIDs,:] ** 2\n",
    "\n",
    "    denum = 1.0 / np.sum(weights, axis=1)\n",
    "\n",
    "    resmap1 = np.sum(weights * res1[indices], axis=1) * denum\n",
    "\n",
    "    if len(onIDs) > 0:\n",
    "        resmap1[onIDs] = res1[indices[onIDs, 0]]\n",
    "    \n",
    "\n",
    "    tree = cKDTree(xyi[iddd]) \n",
    "    score = vals\n",
    "\n",
    "    # On the uniform grid\n",
    "    distances, indices = tree.query(XY, k=3)\n",
    "\n",
    "    onIDs = np.where(distances[:, 0] == 0)[0]\n",
    "    inIDs = np.where(distances[:, 0] > 0)[0]\n",
    "\n",
    "    weights = np.ones(distances.shape)\n",
    "    weights[inIDs,:] = 1.0 / distances[inIDs,:] ** 2\n",
    "\n",
    "    denum = 1.0 / np.sum(weights, axis=1)\n",
    "\n",
    "    score1 = np.sum(weights * score[indices], axis=1) * denum\n",
    "\n",
    "    if len(onIDs) > 0:\n",
    "        score1[onIDs] = score[indices[onIDs, 0]]\n",
    "\n",
    "\n",
    "    return resmap1, score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "current, zscore = result_current_zscore(circuitscape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getis-Ord index\n",
    "\n",
    "We also compute the Getis-Ord Gi* index showing statistically significant connectivity hotspots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_gis(res):\n",
    "    \n",
    "    kd = libpysal.cg.KDTree(np.array(vertices[shelfIDs,:2]))\n",
    "    weights = libpysal.weights.KNN(kd,12)\n",
    "\n",
    "    flow = np.array(res[shelfIDs])\n",
    "\n",
    "    # Gi*\n",
    "    gostars = esda.getisord.G_Local(flow, weights, star=True)\n",
    "\n",
    "    GIs = np.zeros(len(vertices))\n",
    "    GIstar = np.zeros(len(shelfIDs))\n",
    "\n",
    "    # Break observations into significant or not\n",
    "    sig = gostars.p_sim < 0.05\n",
    "    # Plot non-significant clusters\n",
    "    GIstar[(sig==True)] = 0\n",
    "    # Plot HH clusters\n",
    "    GIstar[(gostars.Zs > 0) & (sig==True)] = 5\n",
    "    # Plot LL clusters\n",
    "    GIstar[(gostars.Zs < 0) & (sig==True)] = -5\n",
    "    GIs[shelfIDs] = GIstar\n",
    "    \n",
    "    GIs[GIs>0] = 1\n",
    "    GIs[GIs<0] = -1\n",
    "        \n",
    "    idpos = np.where(GIs == 1)[0]\n",
    "    idneg = np.where(GIs == -1)[0]\n",
    "\n",
    "    combGIs = np.zeros(len(GIs))\n",
    "    combGIs[idpos] = 1\n",
    "    combGIs[idneg] = -1\n",
    "\n",
    "    idzeros = np.where(combGIs == 0)[0]\n",
    "    XY = vertices[:,:2] \n",
    "    tin_tree = cKDTree(XY)\n",
    "\n",
    "    dist, ids = tin_tree.query(XY[idzeros], k=7)\n",
    "    surrounding = np.sum(combGIs[ids],axis=1)\n",
    "\n",
    "    sumsur = np.zeros(len(surrounding))\n",
    "    sumsur[surrounding>2] = 1\n",
    "    sumsur[surrounding<-2] = -1\n",
    "\n",
    "    combGIs[idzeros] = sumsur\n",
    "\n",
    "    return combGIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIstar = result_gis(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output files\n",
    "\n",
    "We now create a `VTK` output containing all connectivity parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get costs \n",
    "costmesh = 'vtk/Sarr700.corridor.cost.vtk'\n",
    "mesh = meshio.read(costmesh)\n",
    "\n",
    "vertices = mesh.points\n",
    "cells = mesh.cells_dict['triangle']\n",
    "elev = mesh.point_data['Z']\n",
    "ED = mesh.point_data['ED']\n",
    "logFA = mesh.point_data['FA']\n",
    "lec = mesh.point_data['costLEC']\n",
    "river_corridor = mesh.point_data['costRiver']\n",
    "cost_elev = mesh.point_data['costElev']\n",
    "totcost = mesh.point_data['all']\n",
    "zscore[elev<0] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VTK` file can be visualised in Paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtkfile = 'vtk/Sarr700.corridor.bio.vtk'\n",
    "vis_mesh = meshio.Mesh(vertices, {'triangle': cells}, \n",
    "                       point_data={\"Z\":elev, \"ED\":ED, \n",
    "                       \"costLEC\":lec, 'FA':logFA, 'costRiver':river_corridor,\n",
    "                       \"costElev\":cost_elev,\"totcost\":totcost,\n",
    "                       \"zscore\":zscore,\"current\":current,\"GIstar\":GIstar,\n",
    "                      })\n",
    "meshio.write(vtkfile, vis_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img width=1000 src=\"img/connectivity_params.png?raw=true\" alt=\"Badlands output\" title=\"Badlands output\"</img>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
